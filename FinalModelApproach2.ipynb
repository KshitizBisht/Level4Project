{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 60, 25, 2)\n",
      "(220, 60, 4)\n",
      "(148, 60, 25, 2)\n",
      "(148, 60, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Loading the pose training and validating data\n",
    "x_train = np.load(\"maleTrain/male_training_data.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"maleTrain/male_training_data_labels.npy\", allow_pickle=True)\n",
    "x_validate = np.load(\"maleTrain/female_training_data.npy\", allow_pickle=True)\n",
    "y_validate = np.load(\"maleTrain/female_training_data_labels.npy\", allow_pickle=True)\n",
    "x_train=np.asarray(x_train).astype(np.float32)\n",
    "y_train=np.asarray(y_train).astype(np.float32)\n",
    "x_validate = np.asarray(x_validate).astype(np.float32)\n",
    "y_validate = np.asarray(y_validate).astype(np.float32)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_9 (TimeDist (None, 60, 25, 64)        448       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 60, 25, 64)        256       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 60, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 60, 12, 64)        12352     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 60, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 60, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 60, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 6, 64)         256       \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 60, 384)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 40)            68000     \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 60, 4)             164       \n",
      "=================================================================\n",
      "Total params: 81,732\n",
      "Trainable params: 81,348\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "(None, 60, 4)\n"
     ]
    }
   ],
   "source": [
    "# CNN + LSTM model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool1D, MaxPool2D\n",
    "import tensorflow as tf\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(TimeDistributed(keras.layers.Conv1D(filters=64, kernel_size=3,padding='same', activation='relu'), input_shape=x_train.shape[1:]))\n",
    "cnn.add(TimeDistributed(BatchNormalization()))\n",
    "cnn.add(TimeDistributed(MaxPooling1D(2,2)))\n",
    "cnn.add(TimeDistributed(keras.layers.Conv1D(filters=64, kernel_size=3,padding='same', activation='relu'), input_shape=x_train.shape[1:]))\n",
    "cnn.add(TimeDistributed(BatchNormalization()))\n",
    "cnn.add(TimeDistributed(MaxPooling1D(2,2)))\n",
    "cnn.add(TimeDistributed(Dropout(0.5)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(TimeDistributed(Flatten()))\n",
    "cnn.add(LSTM(40,unit_forget_bias=0.4, return_sequences=True))\n",
    "cnn.add(TimeDistributed(Dense(4, activation='softmax')))\n",
    "cnn.summary()\n",
    "print(cnn.output_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "adam = Adam(lr=0.0001)\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = cnn.fit(x_train, y_train, validation_data=(x_validate, y_validate), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "cnn.load_weights(\"weights/maleTrained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0472 - accuracy: 0.9976\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4963 - accuracy: 0.8662\n"
     ]
    }
   ],
   "source": [
    "# # validating the model on training and validation data\n",
    "_, train_acc = cnn.evaluate(x_train, y_train)\n",
    "_, val_acc = cnn.evaluate(x_validate,y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = [\"knocking\", \"lifting\", \"throwing\", \"walking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(\"data/ale_knock.npy\", allow_pickle=True)\n",
    "x_test = x_test[:240,...]\n",
    "x_test = np.asarray(x_test).astype(np.float32)\n",
    "x_test = x_test.reshape((4,60,25,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knocking'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yht_pred = cnn.predict(np.asarray(x_test))\n",
    "a = np.argmax(Yht_pred[0],axis = 1)\n",
    "motion[statistics.mode(np.argmax(Yht_pred[1],axis = 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
